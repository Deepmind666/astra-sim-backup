# Q6: 负载集中度分析 - 核心函数注释说明

## 文件信息
- **对应脚本**: `q6_analyze_q6_load_concentration.py`（计算）+ `q6_plot_q6_figures.py`（画图）
- **行号说明**: 以当前脚本为准，本文行号仅作理解辅助
- **核心问题**: 分析不同任务的专家负载集中度,判断负载是否均衡

## 核心问题

### 问题描述
Q6 关注的是**专家负载集中度**(Expert Load Concentration):
- **负载定义**: 每个专家被使用的频率或概率质量
- **核心问题**: 不同任务的负载是否集中在少数专家上?

### 3个核心目标
1. 比较不同任务的"有效专家数 n_eff"
2. 用 Gini / Top-N 覆盖率 / Lorenz 曲线做互证
3. 做长度控制 + 置乱基线,避免混淆因素

### 重要说明
- 本脚本只讨论"负载集中/偏斜",不直接推断"泛化能力强/弱"
- soft 口径来自 Top-(K+2) 概率,是"下界估计"
- hard 口径只看 Top-1 专家频次,是最保守的估计

---

## 核心概念

### 1. 有效专家数 (n_eff)
**定义**: 基于熵的有效专家数量

**公式**:
```
n_eff = 2^H(P)
其中 H(P) = -Σ P * log2(P)
```

**含义**:
- n_eff ≈ 60 → 负载均匀,所有专家都被使用
- n_eff ≈ 10 → 负载集中,只有约10个专家被频繁使用
- n_eff ≈ 1 → 负载极度集中,几乎只用1个专家

**示例**:
```
均匀分布: P = [1/60, 1/60, ..., 1/60]
→ H = log2(60) ≈ 5.9
→ n_eff = 2^5.9 ≈ 60

集中分布: P = [0.5, 0.3, 0.2, 0, 0, ...]
→ H ≈ 1.5
→ n_eff = 2^1.5 ≈ 2.8
```

---

### 2. Gini 系数
**定义**: 衡量分布不均匀程度的指标

**公式**:
```
Gini = (Σ Σ |P_i - P_j|) / (2 * N * Σ P_i)
```

**含义**:
- Gini = 0 → 完全均匀
- Gini = 1 → 完全集中(所有质量在1个专家上)

**与 n_eff 的关系**:
- Gini 高 → n_eff 低(负载集中)
- Gini 低 → n_eff 高(负载均匀)

---

### 3. Top-N 覆盖率
**定义**: 前 N 个专家占据的概率质量

**公式**:
```
Coverage_N = Σ(前N个专家的概率)
```

**示例**:
```
Top-1 覆盖率 = 0.3 → 最常用的专家占30%
Top-5 覆盖率 = 0.7 → 前5个专家占70%
Top-10 覆盖率 = 0.9 → 前10个专家占90%
```

**判定标准**:
- Top-5 > 0.8 → 负载高度集中
- Top-10 > 0.9 → 负载集中
- Top-20 < 0.8 → 负载相对均匀

---

### 4. Lorenz 曲线
**定义**: 累积分布曲线,用于可视化不均匀程度

**构建方法**:
1. 将专家按负载从小到大排序
2. 计算累积比例
3. 绘制曲线

**解读**:
- 曲线越接近对角线 → 分布越均匀
- 曲线越弯曲 → 分布越集中
- 曲线下面积 = (1 - Gini) / 2

---

## 核心函数详解

### 1. 数学工具函数

#### 函数: `safe_normalize()`
**位置**: 第55-60行

**目的**: 安全归一化向量

**算法**:
```python
def safe_normalize(vec: np.ndarray):
    total = float(np.sum(vec))
    if total <= 0:
        # 返回均匀分布
        return np.ones_like(vec) / float(len(vec))
    return vec / total
```

---

#### 函数: `compute_n_eff()`
**位置**: 约第60-80行

**目的**: 计算有效专家数

**算法**:
```python
def compute_n_eff(dist: np.ndarray):
    # 1. 归一化
    dist = safe_normalize(dist)

    # 2. 计算熵
    eps = 1e-12
    dist = np.clip(dist, eps, 1.0)
    H = -np.sum(dist * np.log2(dist))

    # 3. 计算 n_eff
    n_eff = 2 ** H

    return n_eff
```

---

#### 函数: `compute_gini()`
**位置**: 约第80-100行

**目的**: 计算 Gini 系数

**算法**:
```python
def compute_gini(dist: np.ndarray):
    # 1. 归一化
    dist = safe_normalize(dist)

    # 2. 排序
    sorted_dist = np.sort(dist)

    # 3. 计算 Gini
    n = len(sorted_dist)
    index = np.arange(1, n + 1)
    gini = (2 * np.sum(index * sorted_dist)) / (n * np.sum(sorted_dist)) - (n + 1) / n

    return gini
```

---

#### 函数: `compute_top_n_coverage()`
**位置**: 约第100-120行

**目的**: 计算 Top-N 覆盖率

**算法**:
```python
def compute_top_n_coverage(dist: np.ndarray, n_list: List[int]):
    # 1. 归一化
    dist = safe_normalize(dist)

    # 2. 排序(降序)
    sorted_dist = np.sort(dist)[::-1]

    # 3. 计算每个 N 的覆盖率
    coverage = {}
    for n in n_list:
        coverage[n] = float(np.sum(sorted_dist[:n]))

    return coverage
```

---

## 分析流程

### 第一步: 数据加载
1. 加载所有任务的 NPZ 文件
2. 提取 Top-(K+2) 概率和索引
3. 构建专家使用分布

### 第二步: 计算指标
对每个任务计算:
1. **n_eff**: 有效专家数
2. **Gini**: Gini 系数
3. **Top-N 覆盖率**: Top-1, Top-3, Top-5, Top-10, Top-20
4. **Lorenz 曲线**: 累积分布曲线

### 第三步: 长度控制
- 问题: 不同任务的样本长度不同,可能影响结果
- 解决: 对所有任务采样相同数量的 token

### 第四步: 置乱基线
- 问题: 观察到的集中度是否是随机的?
- 解决: 打乱任务标签,重新计算指标

### 第五步: 结果输出
生成 `q6_results.json`,包含:
- 每个任务的所有指标
- 任务间对比
- 置乱基线对比

---

## 实验结论

### 结论1: 任务间负载集中度有差异
**观察**: 不同任务的 n_eff 不同

**示例**:
```
gsm8k: n_eff ≈ 25 (相对均匀)
piqa: n_eff ≈ 15 (较集中)
humaneval: n_eff ≈ 10 (高度集中)
```

**解释**: 某些任务(如代码生成)可能更依赖少数专家

---

### 结论2: Gini / Top-N / n_eff 互相印证
**观察**: 三个指标的结论一致

**示例**:
```
任务A: n_eff高, Gini低, Top-5覆盖率低 → 负载均匀
任务B: n_eff低, Gini高, Top-5覆盖率高 → 负载集中
```

---

### 结论3: 长度控制后结论仍成立
**观察**: 控制样本长度后,任务间差异仍然存在

**解释**: 负载集中度差异不是由样本长度差异导致的

---

### 结论4: 显著高于置乱基线
**观察**: 真实数据的集中度显著高于置乱基线

**解释**: 负载集中不是随机现象,而是任务特性导致的

---

## 与其他问题的关联

### Q2: 任务专属性
- Q2 发现任务有专属专家
- Q6 发现负载集中在少数专家
- **结合**: 专属专家可能承担了大部分负载

### Q3/Q4: 路由动态
- Q3/Q4 发现路由是无记忆的
- Q6 发现负载集中
- **结合**: 虽然路由频繁切换,但仍集中在少数专家

---

## 代码运行示例

```bash
python analyze_q6_load_concentration.py \
    --task gsm8k=/path/to/gsm8k \
    --task piqa=/path/to/piqa \
    --output_dir ./output_q6 \
    --layer 0 \
    --seed 42
```

**输出文件**:
- `q6_results.json`: 完整分析结果

---

**文档创建时间**: 2026-01-19
**作者**: Claude (基于李康锐的原始代码)
